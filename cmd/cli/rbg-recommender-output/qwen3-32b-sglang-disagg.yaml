apiVersion: workloads.x-k8s.io/v1alpha1
kind: RoleBasedGroup
metadata:
    name: qwen3-32b-sglang-pd
spec:
    roles:
        - name: router
          replicas: 1
          template:
            spec:
                containers:
                    - command:
                        - sh
                        - -c
                        - python3 -m sglang_router.launch_router --log-level debug --pd-disaggregation --host 0.0.0.0 --port 8000 --prefill http://qwen3-32b-sglang-pd-prefill-0.s-qwen3-32b-sglang-pd-prefill:8000 34000 --decode http://qwen3-32b-sglang-pd-decode-0.s-qwen3-32b-sglang-pd-decode:8000 --policy random --prometheus-host 0.0.0.0 --prometheus-port 9090
                      image: lmsysorg/sglang-router:v0.2.2
                      name: scheduler
                      volumeMounts:
                        - mountPath: /models/
                          name: model
                volumes:
                    - name: model
                      persistentVolumeClaim:
                        claimName: llm-model
        - name: prefill
          replicas: 2
          template:
            spec:
                containers:
                    - command:
                        - sh
                        - -c
                        - python3 -m sglang.launch_server --model-path /models/QWEN3_32B/ --enable-metrics --disaggregation-mode prefill --port 8000 --disaggregation-bootstrap-port 34000 --host 0.0.0.0 --tp-size 1
                      env:
                        - name: POD_IP
                          valueFrom:
                            fieldRef:
                                fieldPath: status.podIP
                        - name: SGLANG_PORT
                          value: "8000"
                      image: nvcr.io/nvidia/ai-dynamo/sglang-runtime:0.7.0
                      imagePullPolicy: Always
                      name: sglang-prefill
                      ports:
                        - containerPort: 8000
                        - containerPort: 34000
                      readinessProbe:
                        initialDelaySeconds: 30
                        periodSeconds: 10
                        tcpSocket:
                            port: 8000
                      resources:
                        limits:
                            cpu: "8"
                            memory: 56Gi
                            nvidia.com/gpu: "1"
                        requests:
                            cpu: "8"
                            memory: 56Gi
                            nvidia.com/gpu: "1"
                      volumeMounts:
                        - mountPath: /models/
                          name: model
                        - mountPath: /dev/shm
                          name: shm
                volumes:
                    - name: model
                      persistentVolumeClaim:
                        claimName: llm-model
                    - emptyDir:
                        medium: Memory
                        sizeLimit: 32Gi
                      name: shm
        - name: decode
          replicas: 3
          template:
            spec:
                containers:
                    - command:
                        - sh
                        - -c
                        - python3 -m sglang.launch_server --model-path /models/QWEN3_32B/ --enable-metrics --disaggregation-mode decode --port 8000 --host 0.0.0.0 --mem-fraction-static 0.00 --tp-size 2
                      env:
                        - name: POD_IP
                          valueFrom:
                            fieldRef:
                                fieldPath: status.podIP
                        - name: SGLANG_PORT
                          value: "8000"
                      image: nvcr.io/nvidia/ai-dynamo/sglang-runtime:0.7.0
                      imagePullPolicy: Always
                      name: sglang-decode
                      ports:
                        - containerPort: 8000
                      readinessProbe:
                        initialDelaySeconds: 30
                        periodSeconds: 10
                        tcpSocket:
                            port: 8000
                      resources:
                        limits:
                            cpu: "16"
                            memory: 39Gi
                            nvidia.com/gpu: "2"
                        requests:
                            cpu: "16"
                            memory: 39Gi
                            nvidia.com/gpu: "2"
                      volumeMounts:
                        - mountPath: /models/
                          name: model
                        - mountPath: /dev/shm
                          name: shm
                volumes:
                    - name: model
                      persistentVolumeClaim:
                        claimName: llm-model
                    - emptyDir:
                        medium: Memory
                        sizeLimit: 64Gi
                      name: shm
---
apiVersion: v1
kind: Service
metadata:
    labels:
        app: qwen3-32b-sglang-pd
    name: qwen3-32b-sglang-pd
    namespace: default
spec:
    ports:
        - name: http
          port: 8000
          protocol: TCP
          targetPort: 8000
    selector:
        rolebasedgroup.workloads.x-k8s.io/name: qwen3-32b-sglang-pd
        rolebasedgroup.workloads.x-k8s.io/role: router
    type: ClusterIP
